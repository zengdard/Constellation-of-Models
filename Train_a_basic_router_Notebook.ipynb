{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46f0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: soundfile in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (0.12.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (0.10.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from librosa) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from librosa) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\jgoffin.bach2025\\appdata\\roaming\\python\\python39\\site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from pooch>=1.0->librosa) (2.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9059b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1301b4f943e441b4a394523e07dd85c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "#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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d919d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6eec8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompts'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "image_gen_dataset = load_dataset(\"Falah/image_generation_prompts_SDXL\")\n",
    "print(image_gen_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af442eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PD = pd.DataFrame(image_gen_dataset['train'])\n",
    "IMAGE_PD['Label'] = 0\n",
    "IMAGE_PD = IMAGE_PD.rename(columns={'prompts': 'Text'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d87e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PD.head(10)\n",
    "del image_gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89036a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Polaroid photo of a middle-aged woman with fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"glamor photo of a teenage girl with short cur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"high fashion photo of a child with a cute exp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"large format photo of a elderly man with a be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"instant photo of a young man wearing a suit a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"paparazzi photo of a teenage girl with short ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"high fashion photo of a elderly man with a be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"candid photo of a child with a cute expressio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"paparazzi photo of a elderly man with a beard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Polaroid photo of a young man wearing a suit ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  \"Polaroid photo of a middle-aged woman with fa...      0\n",
       "1  \"glamor photo of a teenage girl with short cur...      0\n",
       "2  \"high fashion photo of a child with a cute exp...      0\n",
       "3  \"large format photo of a elderly man with a be...      0\n",
       "4  \"instant photo of a young man wearing a suit a...      0\n",
       "5  \"paparazzi photo of a teenage girl with short ...      0\n",
       "6  \"high fashion photo of a elderly man with a be...      0\n",
       "7  \"candid photo of a child with a cute expressio...      0\n",
       "8  \"paparazzi photo of a elderly man with a beard...      0\n",
       "9  \"Polaroid photo of a young man wearing a suit ...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e906554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dataset = load_dataset(\"stingning/ultrachat\")\n",
    "llm_dataset = pd.DataFrame(llm_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb6a9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dataset.keys()\n",
    "llm_dataset = llm_dataset.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a6980d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dataset['data'] = llm_dataset['data'].apply(lambda x: ' '.join(x[1::2]))###LA MOITIE SERONT COUP2S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75425f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm_dataset = llm_dataset.drop('id', axis=1)\n",
    "llm_dataset = pd.DataFrame(llm_dataset)\n",
    "llm_dataset['Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae3a80ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cross training can benefit groups like runners...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes, there are physical benefits to mindful wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About 71% of the Earth's surface is covered by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Language translation technology has a signific...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As an AI language model, I don't have updated ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  Label\n",
       "0  Cross training can benefit groups like runners...      1\n",
       "1  Yes, there are physical benefits to mindful wa...      1\n",
       "2  About 71% of the Earth's surface is covered by...      1\n",
       "3  Language translation technology has a signific...      1\n",
       "4  As an AI language model, I don't have updated ...      1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f4d9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text', 'Label'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cross training can benefit groups like runners...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes, there are physical benefits to mindful wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About 71% of the Earth's surface is covered by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Language translation technology has a signific...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As an AI language model, I don't have updated ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Collaboration and collective creativity play a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>There are many different types of logical fall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As an AI language model, I do not have persona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As an AI language model, I do not have persona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes, mindful walking can be used as a form of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Cross training can benefit groups like runners...      1\n",
       "1  Yes, there are physical benefits to mindful wa...      1\n",
       "2  About 71% of the Earth's surface is covered by...      1\n",
       "3  Language translation technology has a signific...      1\n",
       "4  As an AI language model, I don't have updated ...      1\n",
       "5  Collaboration and collective creativity play a...      1\n",
       "6  There are many different types of logical fall...      1\n",
       "7  As an AI language model, I do not have persona...      1\n",
       "8  As an AI language model, I do not have persona...      1\n",
       "9  Yes, mindful walking can be used as a form of ...      1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_dataset = llm_dataset.rename(columns={'data': 'Text'})\n",
    "print(llm_dataset.columns)\n",
    "llm_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e7a001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgoffin.bach2025\\AppData\\Local\\miniconda3\\Lib\\site-packages\\datasets\\load.py:2479: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jgoffin.bach2025\\AppData\\Local\\miniconda3\\Lib\\site-packages\\datasets\\load.py:1429: FutureWarning: The repository for speechcolab/gigaspeech contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/speechcolab/gigaspeech\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_data = load_dataset(\"speechcolab/gigaspeech\", \"xs\", use_auth_token=True)\n",
    "\n",
    "\n",
    "train_texts = [item['text'] for item in audio_data['train']]\n",
    "validation_texts = [item['text'] for item in audio_data['validation']]\n",
    "test_texts = [item['text'] for item in audio_data['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9636c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les textes avec des labels\n",
    "combined_texts = []\n",
    "combined_labels = []\n",
    "\n",
    "# Ajouter les donnÃ©es de train avec le label 0\n",
    "combined_texts.extend(train_texts)\n",
    "combined_labels.extend([2] * len(train_texts))\n",
    "\n",
    "# Ajouter les donnÃ©es de validation avec le label 1\n",
    "combined_texts.extend(validation_texts)\n",
    "combined_labels.extend([2] * len(validation_texts))\n",
    "\n",
    "# Ajouter les donnÃ©es de test avec le label 2\n",
    "combined_texts.extend(test_texts)\n",
    "combined_labels.extend([2] * len(test_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b8ec32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA...      2\n",
      "1                              SIX TOMATOES <PERIOD>      2\n",
      "2  AND SOMETHING BROUGHT BACK RESTORED FROM THE R...      2\n",
      "3  TO HELP SCREEN READER USERS IN THE MIDST OF DI...      2\n",
      "4  FOR ALICE HAD READ SEVERAL NICE LITTLE STORIES...      2\n"
     ]
    }
   ],
   "source": [
    "audio_df = pd.DataFrame({\n",
    "    'Text': combined_texts,\n",
    "    'Label': combined_labels\n",
    "})\n",
    "\n",
    "# Affichage des premiÃ¨res lignes pour vÃ©rifier\n",
    "print(audio_df.head())\n",
    "del audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2f3dead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS THEY'RE LEAVING &lt;COMMA&gt; CAN KASH PULL ZAHRA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIX TOMATOES &lt;PERIOD&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND SOMETHING BROUGHT BACK RESTORED FROM THE R...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TO HELP SCREEN READER USERS IN THE MIDST OF DI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOR ALICE HAD READ SEVERAL NICE LITTLE STORIES...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOT BEGGING &lt;PERIOD&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HE PULLS OUT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A CAPACITY KNOWN AS NEUROPLASTICITY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IT SEEMED THE REPORTER HAD JUST BECOME A CHARA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GENERAL HEALTH &lt;COMMA&gt; THE QUALITY OF LIFE &lt;PE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA...      2\n",
       "1                              SIX TOMATOES <PERIOD>      2\n",
       "2  AND SOMETHING BROUGHT BACK RESTORED FROM THE R...      2\n",
       "3  TO HELP SCREEN READER USERS IN THE MIDST OF DI...      2\n",
       "4  FOR ALICE HAD READ SEVERAL NICE LITTLE STORIES...      2\n",
       "5                               NOT BEGGING <PERIOD>      2\n",
       "6                                       HE PULLS OUT      2\n",
       "7                A CAPACITY KNOWN AS NEUROPLASTICITY      2\n",
       "8  IT SEEMED THE REPORTER HAD JUST BECOME A CHARA...      2\n",
       "9  GENERAL HEALTH <COMMA> THE QUALITY OF LIFE <PE...      2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cff0eb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Polaroid photo of a middle-aged woman with fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"glamor photo of a teenage girl with short cur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"high fashion photo of a child with a cute exp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"large format photo of a elderly man with a be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"instant photo of a young man wearing a suit a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"paparazzi photo of a teenage girl with short ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"high fashion photo of a elderly man with a be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"candid photo of a child with a cute expressio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"paparazzi photo of a elderly man with a beard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Polaroid photo of a young man wearing a suit ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  \"Polaroid photo of a middle-aged woman with fa...      0\n",
       "1  \"glamor photo of a teenage girl with short cur...      0\n",
       "2  \"high fashion photo of a child with a cute exp...      0\n",
       "3  \"large format photo of a elderly man with a be...      0\n",
       "4  \"instant photo of a young man wearing a suit a...      0\n",
       "5  \"paparazzi photo of a teenage girl with short ...      0\n",
       "6  \"high fashion photo of a elderly man with a be...      0\n",
       "7  \"candid photo of a child with a cute expressio...      0\n",
       "8  \"paparazzi photo of a elderly man with a beard...      0\n",
       "9  \"Polaroid photo of a young man wearing a suit ...      0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc172a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS THEY'RE LEAVING &lt;COMMA&gt; CAN KASH PULL ZAHRA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIX TOMATOES &lt;PERIOD&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND SOMETHING BROUGHT BACK RESTORED FROM THE R...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TO HELP SCREEN READER USERS IN THE MIDST OF DI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOR ALICE HAD READ SEVERAL NICE LITTLE STORIES...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOT BEGGING &lt;PERIOD&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HE PULLS OUT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A CAPACITY KNOWN AS NEUROPLASTICITY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IT SEEMED THE REPORTER HAD JUST BECOME A CHARA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GENERAL HEALTH &lt;COMMA&gt; THE QUALITY OF LIFE &lt;PE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA...      2\n",
       "1                              SIX TOMATOES <PERIOD>      2\n",
       "2  AND SOMETHING BROUGHT BACK RESTORED FROM THE R...      2\n",
       "3  TO HELP SCREEN READER USERS IN THE MIDST OF DI...      2\n",
       "4  FOR ALICE HAD READ SEVERAL NICE LITTLE STORIES...      2\n",
       "5                               NOT BEGGING <PERIOD>      2\n",
       "6                                       HE PULLS OUT      2\n",
       "7                A CAPACITY KNOWN AS NEUROPLASTICITY      2\n",
       "8  IT SEEMED THE REPORTER HAD JUST BECOME A CHARA...      2\n",
       "9  GENERAL HEALTH <COMMA> THE QUALITY OF LIFE <PE...      2"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_df = pd.concat([audio_df, llm_dataset,IMAGE_PD ], ignore_index=False)\n",
    "#last_df = last_df.drop('id')\n",
    "last_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0df3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "del audio_df,llm_dataset, IMAGE_PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9c4ac5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1fa1cb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510110"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(last_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6e93743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataset,tokenizer, max_len):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        single_row = self.dataset.iloc[idx]\n",
    "        text = single_row.Text\n",
    "        label = single_row.Label\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"comment_text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(), # [1,512] => [512]\n",
    "            \"labels\": int(label)\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2c14bcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97879c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 51200\n",
    "#https://huggingface.co/microsoft/phi-2/blob/main/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ea7bb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = last_df.head(200000)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "\n",
    "# Divisez le dataset en ensembles d'entraÃ®nement et de test\n",
    "train_data, test_data = train_test_split(dataset, test_size=test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6c0ed6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comment_text': 'One popular book series that has been parodied multiple times in popular culture is Harry Potter.\\n\\nExamples of these parodies include:\\n- The famous book series \"Bored of the Rings\" by The Harvard Lampoon which parodied both The Lord of the Rings and Harry Potter. \\n- The TV series \"The Simpsons\" has also included numerous references and parodies, including a Halloween episode where Lisa turns into a witch and enrolls in a wizarding school, which was a parody of Harry Potter. \\n- The film \"Epic Movie\" also included a parody of the Harry Potter series with a character named Harry Beaver. \\n- The TV show \"Robot Chicken\" included a skit called \"Harry Potter: The Musical\" which was a parody of both the books and the movies. \\n- Saturday Night Live has also parodied Harry Potter numerous times on their show, most famously with a skit called \"Hogwarts Academy\" which poked fun at the characters and plot of the series. As an AI language model, I don\\'t have the ability to watch videos or read books. However, I am familiar with these parodies and understand their content and context. As an AI language model designed to answer questions, I don\\'t have personal preferences. However, there are many other Harry Potter parodies out there, including musicals, skits, and even fan-made films. Some popular examples include the \"A Very Potter Musical\" trilogy by Team Starkid, the \"Harry Potter Puppet Pals\" web series, and the \"Wizard People, Dear Reader\" audio commentary by Brad Neely. \"Wizard People, Dear Reader\" is a cult classic audio commentary by Brad Neely that spoofs the first Harry Potter movie. In the commentary, Neely re-imagines the story, adding humorous and absurd elements to the plot and characters. It\\'s a unique and entertaining take on the Harry Potter universe, and it has developed a dedicated following over the years. It\\'s worth noting that the commentary contains adult language and content, so it may not be appropriate for all audiences.', 'input_ids': tensor([ 3198,  2968,  1492,  2168,   326,   468,   587,  1582, 32255,  3294,\n",
      "         1661,   287,  2968,  3968,   318,  5850, 14179,    13,   198,   198,\n",
      "        27730,   286,   777,  1582,  5042,  2291,    25,   198,    12,   383,\n",
      "         5863,  1492,  2168,   366,    33,  1850,   286,   262, 26028,     1,\n",
      "          416,   383, 11131, 28607,  2049,   543,  1582, 32255,  1111,   383,\n",
      "         4453,   286,   262, 26028,   290,  5850, 14179,    13,   220,   198,\n",
      "           12,   383,  3195,  2168,   366,   464, 34376,     1,   468,   635,\n",
      "         3017,  6409, 10288,   290,  1582,  5042,    11,  1390,   257, 16032,\n",
      "         4471,   810, 15378,  4962,   656,   257, 16365,   290, 14627,    82,\n",
      "          287,   257, 18731,   278,  1524,    11,   543,   373,   257, 29695,\n",
      "          286,  5850, 14179,    13,   220,   198,    12,   383,  2646,   366,\n",
      "        13807,   291, 15875,     1,   635,  3017,   257, 29695,   286,   262,\n",
      "         5850, 14179,  2168,   351,   257,  2095,  3706,  5850, 42746,    13,\n",
      "          220,   198,    12,   383,  3195,   905,   366, 14350,   313, 16405,\n",
      "            1,  3017,   257,  1341,   270,  1444,   366, 18308, 14179,    25,\n",
      "          383, 33375,     1,   543,   373,   257, 29695,   286,  1111,   262,\n",
      "         3835,   290,   262,  6918,    13,   220,   198,    12,  3909,  5265,\n",
      "         7547,   468,   635,  1582, 32255,  5850, 14179,  6409,  1661,   319,\n",
      "          511,   905,    11,   749, 20524,   351,   257,  1341,   270,  1444,\n",
      "          366,    39,   519, 26586,  8581,     1,   543, 47320,  1257,   379,\n",
      "          262,  3435,   290,  7110,   286,   262,  2168,    13,  1081,   281,\n",
      "         9552,  3303,  2746,    11,   314,   836,   470,   423,   262,  2694,\n",
      "          284,  2342,  5861,   393,  1100,  3835,    13,  2102,    11,   314,\n",
      "          716,  5385,   351,   777,  1582,  5042,   290,  1833,   511,  2695,\n",
      "          290,  4732,    13,  1081,   281,  9552,  3303,  2746,  3562,   284,\n",
      "         3280,  2683,    11,   314,   836,   470,   423,  2614, 15387,    13,\n",
      "         2102,    11,   612,   389,   867,   584,  5850, 14179,  1582,  5042,\n",
      "          503,   612,    11,  1390, 10530,    82,    11,  1341,   896,    11,\n",
      "          290,   772,  4336,    12,  9727,  7328,    13,  2773,  2968,  6096,\n",
      "         2291,   262,   366,    32,  9576, 14179, 33375,     1, 26298,   416,\n",
      "         4816, 20956,   312,    11,   262,   366, 18308, 14179, 34447,   350,\n",
      "          874,     1,  3992,  2168,    11,   290,   262,   366,    54,  8669,\n",
      "         4380,    11, 23420, 25342,     1,  6597, 14604,   416,  8114,   399,\n",
      "        45269,    13,   366,    54,  8669,  4380,    11, 23420, 25342,     1,\n",
      "          318,   257,  2285,  6833,  6597, 14604,   416,  8114,   399, 45269,\n",
      "          326, 42078,    82,   262,   717,  5850, 14179,  3807,    13,   554,\n",
      "          262, 14604,    11,   399, 45269,   302,    12, 48466,  1127,   262,\n",
      "         1621,    11,  4375, 36102,   290, 12986,  4847,   284,   262,  7110,\n",
      "          290,  3435,    13,   632,   338,   257,  3748,   290, 17774,  1011,\n",
      "          319,   262,  5850, 14179,  6881,    11,   290,   340,   468,  4166,\n",
      "          257,  7256,  1708,   625,   262,   812,    13,   632,   338,  2861,\n",
      "        10820,   326,   262, 14604,  4909,  4044,  3303,   290,  2695,    11,\n",
      "          523,   340,   743,   407,   307,  5035,   329,   477, 15579,    13,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
      "        50295, 50295]), 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset = TextDataset(train_data,tokenizer, max_len=512)\n",
    "test_data = TextDataset(test_data,tokenizer, max_len=512)\n",
    "print(dataset.__getitem__(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "27ffc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pipeline = lambda x: int(x) \n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for x in batch:\n",
    "            label_list.append(label_pipeline(x[\"labels\"]))\n",
    "            processed_text = torch.tensor(x['input_ids'], dtype=torch.int64)\n",
    "            text_list.append(processed_text)\n",
    "            offsets.append(processed_text.size(0))\n",
    "            \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "06e00e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_batch)\n",
    "test_data_loader = DataLoader(test_data, batch_size=16, shuffle=True, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "754f8980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1], device='cuda:0'), tensor([ 5297,    11, 39555,  ...,   460,   307,   281], device='cuda:0'), tensor([   0,  512, 1024, 1536, 2048, 2560, 3072, 3584, 4096, 4608, 5120, 5632,\n",
      "        6144, 6656, 7168, 7680], device='cuda:0'))\n",
      "(tensor([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1], device='cuda:0'), tensor([   16,    13, 47257,  ...,   286,   257,  2128], device='cuda:0'), tensor([   0,  512, 1024, 1536, 2048, 2560, 3072, 3584, 4096, 4608, 5120, 5632,\n",
      "        6144, 6656, 7168, 7680], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgoffin.bach2025\\AppData\\Local\\miniconda3\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "c= 0\n",
    "for batch in dataset_loader:\n",
    "    print(batch)\n",
    "    c +=1\n",
    "    if c == 2 :\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "da57b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Router(nn.Module):\n",
    "    def __init__(self, embed_dim,vocab_size, num_experts, hidden_dim):\n",
    "        super(Router, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc1 = nn.Linear(embed_dim,64)\n",
    "        self.fc2 = nn.Linear(64,16)\n",
    "        self.fc3 = nn.Linear(16, num_experts)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.zero_()\n",
    "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc3.bias.data.zero_()        \n",
    "            \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        x = F.relu(self.fc1(embedded))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "# Initialisation et utilisation du routeur\n",
    "num_experts = 3\n",
    "input_dim = 512\n",
    "router = Router(input_dim,vocab_size, num_experts, hidden_dim=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3ae7ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "\n",
    "loss_fn =nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(router.parameters(), lr=LR)\n",
    "epochs = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11938436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import time \n",
    "\n",
    "i = 0\n",
    "train_loss = 0 \n",
    "total_loss = 0\n",
    "total_accuracy = 0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "batch_times = []\n",
    "accuracies = []\n",
    "\n",
    "total_test_loss = 0\n",
    "total_test_accuracy = 0 \n",
    "avg_test_loss  = 0\n",
    "\n",
    "num_epochs = epochs\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "   \n",
    "    # If you have a validation set, you would also track validation loss and accuracy here\n",
    "\n",
    "    router.train()  # Set the model to training mode\n",
    "    start_time = time.time()\n",
    "    for batch in dataset_loader:\n",
    "        input_prmpt = batch[1]\n",
    "        labels = batch[0]\n",
    "        input_ids, labels = input_prmpt.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = router(input_ids,batch[2] )\n",
    "        \n",
    "        # Compute loss and backpropagate\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        total_accuracy += accuracy_score(labels.cpu(), output.argmax(dim=1).cpu())\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        # Optionally print progress here\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}\")\n",
    "            print(f\"Batch {i + 1}/{len(dataset_loader)}, Loss: {loss.item()}\")\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Time per batch: {elapsed_time:.2f} seconds\")\n",
    "            batch_times.append(elapsed_time)\n",
    "                \n",
    "                \n",
    "        #print('before loss data in training', loss.item(), train_loss)\n",
    "        train_loss = train_loss + ((1 / (i + 1)) * (loss.item() - train_loss))\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(total_accuracy)\n",
    "        \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_data_loader:  # Remplacez test_dataloader par le dataloader de test rÃ©el\n",
    "            input_prmpt = test_batch[1]\n",
    "            labels = test_batch[0]\n",
    "            input_ids, labels = input_prmpt.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = router(input_ids, test_batch[2])\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(output, labels)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            total_test_accuracy += accuracy_score(labels.cpu(), output.argmax(dim=1).cpu())\n",
    "            \n",
    "            \n",
    "\n",
    "    # Calculate average loss and accuracy over the test set\n",
    "    avg_test_loss = total_test_loss / len(test_data_loader)\n",
    "    avg_test_accuracy = total_test_accuracy / len(test_data_loader)\n",
    "    \n",
    "    # Calculate average loss and accuracy over the epoch\n",
    "    avg_loss = total_loss / len(dataset_loader)\n",
    "    avg_accuracy = total_accuracy / len(dataset_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    accuracies.append(avg_accuracy)\n",
    "    \n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"  Average Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"  Average Accuracy: {avg_test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Epoch {epochs + 1}/{num_epochs}, Training Loss: {avg_loss}, Training Accuracy: {avg_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(router.state_dict(), 'router.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env",
   "language": "python",
   "name": "my-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
